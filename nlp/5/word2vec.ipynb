{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:47:51.904769Z",
     "start_time": "2020-07-28T06:47:51.898619Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-28 14:47:51,902 INFO: Use cuda: True, gpu id: 0.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)-15s %(levelname)s: %(message)s')\n",
    "\n",
    "# set seed \n",
    "seed = 666\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set cuda\n",
    "gpu = 0\n",
    "use_cuda = gpu >= 0 and torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(gpu)\n",
    "    device = torch.device(\"cuda\", gpu)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "logging.info(\"Use cuda: %s, gpu id: %d.\", use_cuda, gpu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T06:48:48.500969Z",
     "start_time": "2020-07-28T06:48:26.116000Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-28 14:48:48,479 INFO: Fold lens [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n"
     ]
    }
   ],
   "source": [
    "fold_num = 10\n",
    "data_file = '/home/hy/Documents/tianchi/train_set.csv'\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def all_data2fold(fold_num, num=10000):\n",
    "    fold_data = []\n",
    "    f = pd.read_csv(data_file, sep='\\t', encoding='UTF-8')\n",
    "    texts = f['text'].tolist()[:num]\n",
    "    labels = f['label'].tolist()[:num]\n",
    "\n",
    "    total = len(labels)\n",
    "\n",
    "    index = list(range(total))\n",
    "    np.random.shuffle(index)\n",
    "\n",
    "    all_texts = []\n",
    "    all_labels = []\n",
    "    for i in index:\n",
    "        all_texts.append(texts[i])\n",
    "        all_labels.append(labels[i])\n",
    "\n",
    "    label2id = {}\n",
    "    for i in range(total):\n",
    "        label = str(all_labels[i])\n",
    "        if label not in label2id:\n",
    "            label2id[label] = [i]\n",
    "        else:\n",
    "            label2id[label].append(i)\n",
    "\n",
    "    all_index = [[] for _ in range(fold_num)]\n",
    "    for label, data in label2id.items():\n",
    "        # print(label, len(data))\n",
    "        batch_size = int(len(data) / fold_num)\n",
    "        other = len(data) - batch_size * fold_num\n",
    "        for i in range(fold_num):\n",
    "            cur_batch_size = batch_size + 1 if i < other else batch_size\n",
    "            # print(cur_batch_size)\n",
    "            batch_data = [data[i * batch_size + b] for b in range(cur_batch_size)]\n",
    "            all_index[i].extend(batch_data)\n",
    "\n",
    "    batch_size = int(total / fold_num)\n",
    "    other_texts = []\n",
    "    other_labels = []\n",
    "    other_num = 0\n",
    "    start = 0\n",
    "    for fold in range(fold_num):\n",
    "        num = len(all_index[fold])\n",
    "        texts = [all_texts[i] for i in all_index[fold]]\n",
    "        labels = [all_labels[i] for i in all_index[fold]]\n",
    "\n",
    "        if num > batch_size:\n",
    "            fold_texts = texts[:batch_size]\n",
    "            other_texts.extend(texts[batch_size:])\n",
    "            fold_labels = labels[:batch_size]\n",
    "            other_labels.extend(labels[batch_size:])\n",
    "            other_num += num - batch_size\n",
    "        elif num < batch_size:\n",
    "            end = start + batch_size - num\n",
    "            fold_texts = texts + other_texts[start: end]\n",
    "            fold_labels = labels + other_labels[start: end]\n",
    "            start = end\n",
    "        else:\n",
    "            fold_texts = texts\n",
    "            fold_labels = labels\n",
    "\n",
    "        assert batch_size == len(fold_labels)\n",
    "\n",
    "        # shuffle\n",
    "        index = list(range(batch_size))\n",
    "        np.random.shuffle(index)\n",
    "\n",
    "        shuffle_fold_texts = []\n",
    "        shuffle_fold_labels = []\n",
    "        for i in index:\n",
    "            shuffle_fold_texts.append(fold_texts[i])\n",
    "            shuffle_fold_labels.append(fold_labels[i])\n",
    "\n",
    "        data = {'label': shuffle_fold_labels, 'text': shuffle_fold_texts}\n",
    "        fold_data.append(data)\n",
    "\n",
    "    logging.info(\"Fold lens %s\", str([len(data['label']) for data in fold_data]))\n",
    "\n",
    "    return fold_data\n",
    "\n",
    "\n",
    "fold_data = all_data2fold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:09:54.159635Z",
     "start_time": "2020-07-28T09:09:54.155879Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-28 17:09:54,157 INFO: Total 9000 docs.\n"
     ]
    }
   ],
   "source": [
    "# build train data for word2vec\n",
    "fold_id = 9\n",
    "\n",
    "train_texts = []\n",
    "for i in range(0, fold_id):\n",
    "    data = fold_data[i]\n",
    "    train_texts.extend(data['text'])\n",
    "    \n",
    "logging.info('Total %d docs.' % len(train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:13:15.189909Z",
     "start_time": "2020-07-28T09:12:54.042716Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-28 17:12:54,045 INFO: Start training...\n",
      "2020-07-28 17:12:55,871 INFO: 'pattern' package not found; tag filters are not available for English\n",
      "2020-07-28 17:12:56,980 INFO: collecting all words and their counts\n",
      "2020-07-28 17:12:56,981 INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-07-28 17:12:58,207 INFO: collected 5295 word types from a corpus of 8191447 raw words and 9000 sentences\n",
      "2020-07-28 17:12:58,207 INFO: Loading a fresh vocabulary\n",
      "2020-07-28 17:12:58,223 INFO: effective_min_count=5 retains 4335 unique words (81% of original 5295, drops 960)\n",
      "2020-07-28 17:12:58,224 INFO: effective_min_count=5 leaves 8189498 word corpus (99% of original 8191447, drops 1949)\n",
      "2020-07-28 17:12:58,238 INFO: deleting the raw counts dictionary of 5295 items\n",
      "2020-07-28 17:12:58,239 INFO: sample=0.001 downsamples 61 most-common words\n",
      "2020-07-28 17:12:58,239 INFO: downsampling leaves estimated 7070438 word corpus (86.3% of prior 8189498)\n",
      "2020-07-28 17:12:58,251 INFO: estimated required memory for 4335 words and 100 dimensions: 5635500 bytes\n",
      "2020-07-28 17:12:58,251 INFO: resetting layer weights\n",
      "2020-07-28 17:12:58,308 INFO: training model with 8 workers on 4335 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-07-28 17:12:59,317 INFO: EPOCH 1 - PROGRESS: at 29.57% examples, 2072191 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-28 17:13:00,322 INFO: EPOCH 1 - PROGRESS: at 60.97% examples, 2130363 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-28 17:13:01,325 INFO: EPOCH 1 - PROGRESS: at 91.73% examples, 2144234 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-28 17:13:01,561 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-28 17:13:01,567 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-28 17:13:01,569 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-28 17:13:01,575 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-28 17:13:01,581 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-28 17:13:01,583 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-28 17:13:01,585 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-28 17:13:01,586 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-28 17:13:01,587 INFO: EPOCH - 1 : training on 8191447 raw words (7022031 effective words) took 3.3s, 2144617 effective words/s\n",
      "2020-07-28 17:13:02,600 INFO: EPOCH 2 - PROGRESS: at 29.16% examples, 2033550 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-28 17:13:03,602 INFO: EPOCH 2 - PROGRESS: at 59.64% examples, 2075312 words/s, in_qsize 16, out_qsize 0\n",
      "2020-07-28 17:13:04,604 INFO: EPOCH 2 - PROGRESS: at 90.37% examples, 2113203 words/s, in_qsize 13, out_qsize 2\n",
      "2020-07-28 17:13:04,900 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-28 17:13:04,902 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-28 17:13:04,904 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-28 17:13:04,906 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-28 17:13:04,912 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-28 17:13:04,916 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-28 17:13:04,919 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-28 17:13:04,919 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-28 17:13:04,920 INFO: EPOCH - 2 : training on 8191447 raw words (7020797 effective words) took 3.3s, 2109204 effective words/s\n",
      "2020-07-28 17:13:05,929 INFO: EPOCH 3 - PROGRESS: at 28.47% examples, 1992453 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-28 17:13:06,941 INFO: EPOCH 3 - PROGRESS: at 57.94% examples, 2008288 words/s, in_qsize 13, out_qsize 2\n",
      "2020-07-28 17:13:07,944 INFO: EPOCH 3 - PROGRESS: at 87.58% examples, 2046555 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-28 17:13:08,326 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-28 17:13:08,330 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-28 17:13:08,332 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-28 17:13:08,333 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-28 17:13:08,333 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-28 17:13:08,342 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-28 17:13:08,345 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-28 17:13:08,347 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-28 17:13:08,348 INFO: EPOCH - 3 : training on 8191447 raw words (7021316 effective words) took 3.4s, 2050827 effective words/s\n",
      "2020-07-28 17:13:09,362 INFO: EPOCH 4 - PROGRESS: at 29.90% examples, 2095412 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-28 17:13:10,368 INFO: EPOCH 4 - PROGRESS: at 59.78% examples, 2080171 words/s, in_qsize 16, out_qsize 1\n",
      "2020-07-28 17:13:11,368 INFO: EPOCH 4 - PROGRESS: at 90.39% examples, 2114144 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-28 17:13:11,649 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-28 17:13:11,652 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-28 17:13:11,653 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-28 17:13:11,655 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-28 17:13:11,660 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-28 17:13:11,662 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-28 17:13:11,667 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-28 17:13:11,670 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-28 17:13:11,671 INFO: EPOCH - 4 : training on 8191447 raw words (7021674 effective words) took 3.3s, 2119063 effective words/s\n",
      "2020-07-28 17:13:12,684 INFO: EPOCH 5 - PROGRESS: at 31.20% examples, 2181006 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-28 17:13:13,690 INFO: EPOCH 5 - PROGRESS: at 61.60% examples, 2157671 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-28 17:13:14,696 INFO: EPOCH 5 - PROGRESS: at 92.89% examples, 2165910 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-28 17:13:14,902 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-28 17:13:14,904 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-28 17:13:14,905 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-28 17:13:14,906 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-28 17:13:14,907 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-28 17:13:14,910 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-28 17:13:14,915 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-28 17:13:14,919 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-28 17:13:14,919 INFO: EPOCH - 5 : training on 8191447 raw words (7021417 effective words) took 3.2s, 2168336 effective words/s\n",
      "2020-07-28 17:13:14,922 INFO: training on a 40957235 raw words (35107235 effective words) took 16.6s, 2113231 effective words/s\n",
      "2020-07-28 17:13:14,923 INFO: precomputing L2-norms of word weight vectors\n",
      "2020-07-28 17:13:15,113 INFO: saving Word2Vec object under ./word2vec.bin, separately None\n",
      "2020-07-28 17:13:15,114 INFO: not storing attribute vectors_norm\n",
      "2020-07-28 17:13:15,115 INFO: not storing attribute cum_table\n",
      "2020-07-28 17:13:15,187 INFO: saved ./word2vec.bin\n"
     ]
    }
   ],
   "source": [
    "logging.info('Start training...')\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "num_features = 100     # Word vector dimensionality\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "\n",
    "train_texts = list(map(lambda x: list(x.split()), train_texts))\n",
    "model = Word2Vec(train_texts, workers=num_workers, size=num_features)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# save model\n",
    "model.save(\"./word2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:13:55.862353Z",
     "start_time": "2020-07-28T09:13:55.468181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-28 17:13:55,469 INFO: loading Word2Vec object from ./word2vec.bin\n",
      "2020-07-28 17:13:55,499 INFO: loading wv recursively from ./word2vec.bin.wv.* with mmap=None\n",
      "2020-07-28 17:13:55,499 INFO: setting ignored attribute vectors_norm to None\n",
      "2020-07-28 17:13:55,500 INFO: loading vocabulary recursively from ./word2vec.bin.vocabulary.* with mmap=None\n",
      "2020-07-28 17:13:55,501 INFO: loading trainables recursively from ./word2vec.bin.trainables.* with mmap=None\n",
      "2020-07-28 17:13:55,501 INFO: setting ignored attribute cum_table to None\n",
      "2020-07-28 17:13:55,502 INFO: loaded ./word2vec.bin\n",
      "2020-07-28 17:13:55,509 INFO: storing 4335x100 projection weights into ./word2vec.txt\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = Word2Vec.load(\"./word2vec.bin\")\n",
    "\n",
    "# convert format\n",
    "model.wv.save_word2vec_format('./word2vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model.wv.load_word2vec_format('/home/hy/Documents/tianchi/word2vec.txt', binary=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.wv['6758']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:17:38.055784Z",
     "start_time": "2020-07-28T09:17:37.385719Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-28 17:17:37,386 INFO: loading projection weights from /home/hy/Documents/tianchi/word2vec.txt\n",
      "2020-07-28 17:17:38,048 INFO: loaded (5976, 100) matrix from /home/hy/Documents/tianchi/word2vec.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7f7df71f1978>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:20:24.519913Z",
     "start_time": "2020-07-28T09:20:24.482439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06302957, -0.0816782 ,  0.12224683,  0.05743894,  0.09141383,\n",
       "        0.08220726,  0.133415  , -0.02033619,  0.12548573,  0.14604083,\n",
       "       -0.06880651, -0.04293273, -0.07917397,  0.08346818,  0.05931692,\n",
       "        0.01149672, -0.13207817,  0.03288741, -0.00528292,  0.1524673 ,\n",
       "       -0.08425879,  0.00353841,  0.09706791,  0.14164776,  0.14601718,\n",
       "        0.12156782,  0.05306974, -0.03622913,  0.03124568, -0.13916202,\n",
       "       -0.03997386,  0.023746  , -0.08548971, -0.09077025,  0.08922168,\n",
       "       -0.12293343, -0.11359778,  0.05834633, -0.05858888, -0.05669861,\n",
       "        0.02146043, -0.09480041, -0.04206865,  0.00633098,  0.02165185,\n",
       "        0.04812855,  0.08169613,  0.03259791,  0.01674422, -0.07448601,\n",
       "        0.1639229 ,  0.02134857,  0.05822015, -0.07742783,  0.0232669 ,\n",
       "        0.21945013, -0.11466961,  0.04866209,  0.08020634, -0.09274981,\n",
       "        0.04626997,  0.12170841, -0.12567827, -0.06670913, -0.11654548,\n",
       "        0.0465796 ,  0.08097442, -0.1162102 , -0.258183  ,  0.04069211,\n",
       "        0.16691978,  0.0097614 ,  0.02916357,  0.13039133, -0.16678508,\n",
       "       -0.035724  , -0.03972628, -0.13243811,  0.08345193,  0.00804747,\n",
       "        0.11915357,  0.06152429, -0.02230228, -0.3355758 , -0.04764537,\n",
       "        0.05292045, -0.09662194, -0.10365219, -0.03443296,  0.02525833,\n",
       "       -0.05132434,  0.21461609,  0.04524432,  0.01160559, -0.18121028,\n",
       "        0.01269484,  0.17462845, -0.05998255, -0.09885245,  0.05276561],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['6758']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}